version: '3'

volumes:
  model-data:

services:
  api-cuda-11-5:
    image: rip-current-detection:cuda11-5
    # profiles: [ "cuda11-5" ]
    build:
      context:      .
      dockerfile:   Dockerfile.cuda-11.5
    ports:
     - 8888:8000
    tmpfs:
     - "/outputs"
    environment:
     - OUTPUT_DIRECTORY=/outputs
    volumes:
      - "model-data:/root/.cache/torch:rw"
    # Optional: nvidia GPU hardware support
    runtime: 'nvidia'
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities: [
              # 'gpu',
              'compute',
              # 'video',
              'utility'
            ]
            count: 1
    command: >
      gunicorn api:app
        --bind "0.0.0.0:8000"
        --timeout 240
        -w 1 --max-requests 10000
        --access-logfile -
        --error-logfile -
        -k worker.LimitedConcurrencyUvicornWorker
